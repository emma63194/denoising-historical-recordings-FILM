# 🎯 老電影音頻降噪訓練總結

## 📅 訓練日期：2026年2月3日

---

## 🚀 專案目標
將黑膠唱片降噪專案改造為**老電影音頻降噪系統**，使用多樣化資料集（語音 + 音效 + 音樂）訓練 U-Net 模型。

---

## 💻 硬體環境
- **裝置**：MacBook Air M3
- **記憶體**：16GB 統一記憶體
- **GPU**：Apple M3（8-10 核心）+ Metal 加速
- **儲存**：外接 SSD (SP SSD 120)

---

## 📊 資料集配置

### Prototype 配置（快速驗證）
| 類型 | 資料集 | 訓練檔案數 | 用途 |
|------|--------|-----------|------|
| 🗣️ 語音 | AISHELL-3 (SSB0005, SSB0009) | 963 | 對白降噪 |
| 🔊 音效 | FSD50K (dev) | 36,846 | 環境音降噪 |
| 🎵 音樂 | MusicNet (train) | 320 | 配樂降噪 |
| 📼 噪音 | Gramophone Record Noise | 2,427 | 模擬老電影噪音 |

**混合比例**：60% 語音 + 20% 音效 + 20% 音樂

### 驗證集
- 語音：SSB0005 測試集（~50 檔案）
- 音效：FSD50K eval（前 50 檔案）
- 音樂：MusicNet test（~50 檔案）
- **總計**：~150 檔案，591 個片段

---

## 🔧 模型配置

### U-Net 架構（M3 優化版）
```yaml
模型參數：1,880,388（7.17 MB）
- num_tfc: 1（減少計算複雜度）
- depth: 3
- num_stages: 2
- STFT: win_size=2048, hop_size=441
```

### 訓練超參數
```yaml
Batch Size: 4（M3 16GB 記憶體優化）
Epochs: 8（Prototype 快速驗證）
Steps per Epoch: 80
Learning Rate: 2e-4（加快收斂）
Optimizer: Adam (beta1=0.5, beta2=0.9)
Loss Function: MAE (Mean Absolute Error)
Segment Length: 3 秒（訓練）/ 8 秒（測試）
```

---

## 📈 訓練歷程

### 第一次完整訓練（06:39-07:55）
**狀態**：✅ 成功完成，但模型未保存

| Epoch | Train Loss | Train MAE | Val Loss | Val MAE | 時間 |
|-------|-----------|-----------|----------|---------|------|
| 1 | 0.6029 | 0.3427 | 0.5137 | 0.2896 | 06:39-06:48 |
| 2 | 0.3184 | 0.1871 | 0.4060 | 0.2356 | 06:48-06:58 |
| 3 | 0.2985 | 0.1711 | 0.3370 | 0.1882 | 06:58-07:08 |
| 4 | 0.1787 | 0.1023 | 0.3003 | 0.1668 | 07:08-07:18 |
| 5 | 0.2174 | 0.1158 | 0.2651 | 0.1412 | 07:18-07:28 |
| 6 | 0.1886 | 0.0980 | 0.2486 | 0.1296 | 07:28-07:38 |
| 7 | 0.1853 | 0.0941 | 0.2303 | 0.1177 | 07:38-07:48 |
| 8 | 0.1197 | 0.0609 | 0.2280 | 0.1169 | 07:48-07:55 |

**總訓練時間**：約 1 小時 16 分鐘

**性能表現**：
- ✅ 快速收斂：Epoch 1-4 驗證 MAE 從 0.29 → 0.17（41% 改善）
- ✅ 穩定學習：Epoch 4-8 持續優化至 0.117
- ✅ 無明顯過擬：最終驗證 loss 仍在下降
- ⚠️ Epoch 5 輕微波動（訓練 loss 回升）
- ❌ 問題：Checkpoint 設定每 50 epochs 保存，導致模型未保存

### 第二次訓練（08:06-09:27）
**狀態**：✅ 成功完成並保存模型
**SNR 設定**：uniform(2, 20) dB

**改進**：
- 修改 checkpoint 策略：每個 epoch 自動保存最佳模型
- 每 10 epochs 或最後一個 epoch 額外備份
- 訓練數據快取機制生效（加載時間 < 10 秒）

**保存的模型**：
```
experiments/prototype/
├── checkpoint                           # 最佳模型（基於驗證 loss）
├── checkpoint.data-00000-of-00001      # 7.2 MB
├── checkpoint.index                     # 7.1 KB
├── checkpoint_epoch_8.data-00000-of-00001  # 最終 epoch 備份
└── checkpoint_epoch_8.index
```

**保存時間**：
- 最佳模型：08:16（推測 Epoch 1-3 之間）
- 最終模型：09:27（Epoch 8 完成）

**推論測試結果**：
- ❌ **嚴重問題**：模型移除了約 90% 的原始信號
- 測試檔案：test.wav（較乾淨）、test_2.wav（較髒）
- 相關性分析：原始 vs 殘差 = 0.9982（殘差包含幾乎所有原始信號）
- **根本原因**：SNR 2-20 dB 訓練範圍不當
  - SNR 2-5 dB 的訓練樣本噪音過強，蓋過原始信號
  - 模型學到錯誤策略：「輸出接近零最安全，可以最小化 MAE」
  - 實際老電影 SNR 通常在 10-25 dB 範圍

### 第三次訓練（2026年2月4日 05:31-06:40）
**狀態**：✅ 成功完成並保存模型
**SNR 設定**：uniform(10, 25) dB（調整後）

**調整原因**：
1. 前次訓練（SNR 2-20）模型過度移除信號
2. SNR 2-5 dB 屬於極端噪音環境，不符合老電影實際情況
3. 調整為 10-25 dB 更接近真實老電影音質

**訓練結果**：

| Epoch | Train Loss | Train MAE | Val Loss | Val MAE | 備註 |
|-------|-----------|-----------|----------|---------|------|
| 1 | 0.4200 | 0.2774 | 0.5314 | 0.2962 | 初始化階段 |
| 2 | 0.2512 | 0.1686 | 0.4641 | 0.2535 | 快速收斂 |
| 3 | 0.2392 | 0.1539 | 0.3912 | 0.2112 | - |
| 4 | 0.2063 | 0.1274 | 0.3143 | 0.1676 | - |
| 5 | 0.2420 | 0.1430 | **0.2746** | **0.1360** | **最佳模型** ✅ |
| 6 | 0.1117 | 0.0642 | 0.2932 | 0.1442 | Val loss 回升 |
| 7 | 0.0822 | 0.0481 | 0.2680 | 0.1308 | - |
| 8 | 0.0817 | 0.0479 | 0.2661 | 0.1293 | 最終 epoch |

**總訓練時間**：約 1 小時 9 分鐘（05:31-06:40）

**性能分析**：
- ✅ 穩定收斂：Val MAE 從 0.296 → 0.129（56% 改善）
- ✅ 最佳表現：Epoch 5 達到 Val Loss 0.2746
- ⚠️ Epoch 6-8：驗證 loss 略有波動，可能接近過擬合邊緣
- 📊 **與 SNR 2-20 模型對比**：
  - SNR 2-20：Val MAE 0.117（更低但不實用）
  - SNR 10-25：Val MAE 0.129（略高但理論上更實用）

**訓練速度**：
- 首步編譯：~11.7 秒（graph compilation）
- 平均每步：~4 秒（穩定後）
- 每個 epoch：~8.5 分鐘（5.5分鐘訓練 + 3分鐘驗證）
- 總時間：69 分鐘（8 epochs）

**推論測試**：
- 測試時間：11:54（2026/02/04）
- 測試檔案：test_2.wav（44MB，較髒的老電影音訊）
- 處理速度：~1.65 it/s（53 segments，32秒完成）
- 降噪強度：1.0（完全模型輸出）
- **使用者反饋**：⚠️ 感覺跟第一次訓練（SNR 2-20）一樣，沒有明顯改善

**問題分析**：
- ❓ **為何 SNR 調整後效果仍不佳？**
  1. **噪音類型不匹配**：Gramophone 唱片噪音 ≠ 老電影噪音
     - Gramophone：主要是爆裂聲、刮擦聲、底噪
     - 老電影：可能包含磁帶噪音、光學音軌噪音、數位化噪音
  2. **訓練策略問題**：「乾淨音訊 + 人工噪音」的合成方式可能不夠真實
  3. **MAE Loss 限制**：均方誤差可能無法捕捉人耳感知的音質差異
  4. **模型架構限制**：U-Net 可能需要更多上下文資訊（更長的時間窗口）

**保存的模型**：
```
experiments/prototype/
├── checkpoint                           # 最佳模型（Epoch 5）
├── checkpoint.data-00000-of-00001      # 7.2 MB
├── checkpoint.index                     # 7.1 KB  
├── checkpoint_epoch_8.data-00000-of-00001  # 最終 epoch 備份
└── checkpoint_epoch_8.index
```

### 第四次訓練（2026年2月24-25日）
**狀態**：✅ 成功完成並保存模型
**SNR 設定**：uniform(10, 25) dB（與第三次相同）

**調整原因**：
1. 前三次訓練顯示降噪效果不足
2. 增加訓練強度（更多 epochs 和 steps）
3. 擴大驗證集規模，提升評估可靠性

**訓練配置變更**：
```yaml
epochs: 20                 # 從 8 增加到 20
steps_per_epoch: 200      # 從 80 增加到 200
learning_rate: 2e-4       # 保持不變
batch_size: 4             # 保持不變
seg_len_s_train: 3        # 保持不變
```

**驗證集擴展**：
- **語音**：AISHELL-3 6 個驗證說話者完整集
  - SSB0005, SSB0009, SSB0012, SSB0016, SSB0018, SSB0043
  - 檔案數：~150 → **完整集**
- **音效**：FSD50K eval 集
  - 原始 9,692 檔案 → **限制 500 檔案**（避免驗證時間過長）
- **音樂**：MusicNet test 集
  - 檔案數：~50 → **完整集**
- **總計擴展**：150 檔案 → **628 檔案**（4.2x 增加）

**訓練結果**：

| Epoch | Train MAE | Val MAE | 備註 |
|-------|-----------|---------|------|
| 1-5 | 逐步下降 | 逐步下降 | 初期快速收斂 |
| 10 | ~0.10 | ~0.15 | 中期穩定 |
| 15 | ~0.09 | ~0.155 | 驗證 loss 平穩 |
| 20 | ~0.08 | **0.156** | **最終模型** ✅ |

**訓練時間**：
- 開始：2026/02/24 晚上
- 結束：2026/02/25 早上
- **總時長**：約 **8.5 小時**（20 epochs × 200 steps）
- 平均每 epoch：~25.5 分鐘
- 平均每 step：~7.6 秒

**推論測試結果**：
- 測試時間：2026/02/25
- 測試檔案：test_2.wav（老電影音訊）
- 降噪強度：0.3（denoising_strength）
- **使用者反饋**：⚠️ **「降噪效果有限，雖然改進聲音變小的問題，但現在跟沒降噪差不多」**

**性能分析與問題**：
- ✅ 訓練穩定：20 epochs 收斂良好，無明顯過擬合
- ✅ 聲音音量改善：不再像第二、三次訓練那樣過度移除信號
- ❌ **降噪效果不足**：幾乎無法察覺噪音移除
- 📊 **Val MAE 悖論**：
  - 第二/三次訓練：Val MAE 0.129（更低但過度降噪）
  - 第四次訓練：Val MAE 0.156（更高但降噪不足）
  - **結論**：MAE loss 無法反映實際感知質量

**深層問題診斷**：
1. **訓練數據增加可能造成反效果**：
   - 驗證集從 150 → 628 檔案（4.2x）
   - 更多樣化的資料讓模型變得**保守**
   - 為了在所有樣本上取得好的 MAE，模型選擇「少做少錯」策略
   
2. **根本問題依然存在**：
   - Gramophone 噪音 ≠ 老電影噪音（類型不匹配）
   - MAE loss 優化方向 ≠ 人耳感知質量
   - 缺乏真實老電影配對資料（noisy → clean）

3. **可能的改進方向**：
   - 調整學習率使模型更積極
   - 減少 SNR 範圍（回到 5-15 dB？）
   - 添加感知損失函數（STFT、multi-scale loss）
   - 使用更具針對性的噪音資料集

**保存的模型**：
```
experiments/prototype/
├── checkpoint                           # 最佳模型（Epoch ?）
├── checkpoint.data-00000-of-00001      # 7.2 MB
├── checkpoint.index                     # 7.1 KB
└── [可能有最終 epoch 備份]
```

---

## 🔧 改進功能：可調式降噪強度

**動機**：發現 SNR 2-20 模型過度移除信號後，實作彈性調整功能

**實作方式**：
```python
# 配置：conf_prototype.yaml
inference:
  denoising_strength: 0.3  # 0.0-1.0

# 混合公式
output = strength * denoised + (1 - strength) * original
```

**檔名規則**（避免覆蓋）：
- 強度 = 1.0：`test_denoised.wav`（預設）
- 強度 = 0.3：`test_denoised_s3.wav`
- 強度 = 0.5：`test_denoised_s5.wav`
- 強度 = 0.7：`test_denoised_s7.wav`

**使用範例**：
```bash
# 溫和降噪（建議用於測試）
python3 inference.py --config-name conf_prototype \
  inference.audio=test_audio/file.wav \
  inference.denoising_strength=0.3

# 中等降噪
inference.denoising_strength=0.5

# 強力降噪（完全模型輸出）
inference.denoising_strength=1.0
```

**優點**：
- ✅ 即使模型效果不佳，仍可保留更多原始信號
- ✅ 無需重新訓練即可調整降噪程度
- ✅ 適應不同噪音等級的音檔
- ✅ 檔名不會互相覆蓋，方便比較

---

## 🎯 關鍵技術突破

### 1. 資料快取機制
**問題**：每次訓練都要重新載入和 framify 數千個音檔（3-4 分鐘）

**解決方案**：
```python
# 快取檔案：.cache/dataset/val_data_validation_{hash}.pkl
- 基於配置生成 MD5 hash
- 首次載入：~1-2 分鐘處理 + 保存
- 後續載入：~5-10 秒直接讀取
- 快取大小：~500 MB（591 片段）
```

### 2. 智能資料集識別
**問題**：配置可能包含不同數量的路徑

**解決方案**：
```python
# 通過路徑關鍵字自動分類
if "aishell" in path: → 語音
if "fsd50k" in path:  → 音效
if "musicnet" in path: → 音樂
```

### 3. 噪音生成器自動適配
**問題**：Gramophone 資料集沒有 CSV 元數據

**解決方案**：
```python
# 自動檢測並切換模式
if os.path.exists("info.csv"):
    使用 CSV 模式
else:
    直接遞迴讀取所有 WAV 檔案
```

### 4. 縮排錯誤修正
**問題**：Mono 音檔跳過處理導致無限循環

**解決方案**：
```python
# 修正前：normalize/framify 在 if len(shape)>1 內
# 修正後：移出條件判斷，確保所有音檔都處理
```

---

## 📊 效能分析

### GPU 利用率
- 每個 training step：~4-5 秒
- 每個 validation step：~1.4 秒
- GPU 初始化：Metal device 正常運作
- 計算圖編譯：首個 step ~25 秒

### 記憶體使用
- 訓練時：未發生 OOM（batch_size=4 安全）
- 驗證快取：~500 MB
- 模型大小：7.2 MB

### 訓練時間分佈
- 單個 epoch 訓練：~6 分鐘（80 steps × 4.5s）
- 單個 epoch 驗證：~3.5 分鐘（148 batches × 1.4s）
- 總計每 epoch：~9.5 分鐘
- 8 epochs 總時間：~76 分鐘

---

## ⚠️ 遇到的問題與解決

### 問題列表
1. ❌ Hydra 配置語法錯誤（舊版 → 新版）
2. ❌ 路徑格式不匹配（glob 模式 vs 目錄）
3. ❌ 驗證集檔案數為 0（speaker 選擇錯誤）
4. ❌ 記憶體 OOM（batch_size 過大）
5. ❌ 訓練卡住（mono 音檔縮排錯誤）
6. ❌ 模型未保存（checkpoint 頻率設定問題）
7. ❌ 快取過大（驗證集太多檔案）
8. ❌ **SNR 2-20 模型過度移除信號**（移除 90%）
9. ❌ 訓練初期誤判為卡住（實為 graph compilation，需等待~11秒）
10. ❌ **SNR 10-25 模型效果仍不佳**（與 SNR 2-20 感覺相同）
11. ❌ Inference 檔名會互相覆蓋（不同降噪強度）

### 解決方案
1. ✅ 更新為 `@hydra.main(version_base=None)`
2. ✅ 改用目錄路徑而非 glob 模式
3. ✅ 選擇檔案數多的 speaker（SSB0005/0009）
4. ✅ 降低 batch_size: 16 → 4
5. ✅ 修正縮排，確保所有音檔都處理
6. ✅ 改為每 epoch 自動保存最佳模型
7. ✅ 限制每個路徑最多 50 檔案 + 快取機制
8. ✅ 調整 SNR 為 10-25 dB（理論改善，但實測效果有限）
9. ✅ 耐心等待首步編譯完成，後續會自動加速
10. ⚠️ **待解決**：可能需要更換噪音源或改變訓練策略
11. ✅ 實作檔名後綴（強度 0.3 → `_s3`，避免覆蓋）

---

## ✅ 訓練成果總結

### 三次訓練比較

| 訓練次數 | SNR 範圍 | Val MAE（最佳） | 狀態 | 推論效果 |
|---------|----------|----------------|------|---------|
| 第一次 | 2-20 dB | 0.117 | ❌ 未保存 | - |
| 第二次 | 2-20 dB | 0.117 | ✅ 已保存 | ❌ 移除 90% 信號 |
| 第三次 | 10-25 dB | 0.129 | ✅ 已保存 | ⚠️ 效果仍不理想 |

### 模型性能
- **第二次訓練模型**（SNR 2-20）：
  - 最佳驗證 MAE：0.117
  - 問題：過度移除信號，不實用
  
- **第三次訓練模型**（SNR 10-25）：
  - 最佳驗證 MAE：0.129
  - 問題：效果與 SNR 2-20 相似，未顯著改善

### 已保存的模型
```
experiments/prototype/checkpoint  # 第三次訓練（SNR 10-25）
```

### 核心問題
**Loss 收斂 ≠ 實用模型**：
- 訓練 MAE 持續下降 ✅
- 驗證 MAE 穩定改善 ✅  
- 實際降噪效果不佳 ❌

**根本原因**：
1. **訓練數據與真實數據不匹配**
   - 訓練：乾淨音訊 + Gramophone 噪音
   - 測試：真實老電影音訊（噪音特性不同）
2. **Loss 函數限制**
   - MAE 無法反映人耳感知品質
   - 模型可能學到「安全策略」：輸出接近零或過度平滑
3. **噪音源問題**
   - Gramophone 噪音：爆裂聲、刮擦聲
   - 老電影噪音：可能包含磁帶噪音、光學音軌噪音等

---

## 🚀 建議後續步驟

### 當前狀態評估
- ✅ 訓練流程已完全打通（M3 環境、快取機制、checkpoint）
- ✅ 模型可以成功收斂（Loss 和 MAE 都正常下降）
- ❌ **實際降噪效果不理想**（SNR 2-20 和 10-25 都類似）

### 選項 A：更換噪音源（推薦）⭐
**問題根源**：Gramophone 噪音 ≠ 老電影噪音

**建議方案**：
1. 收集真實老電影音訊樣本（有噪音的）
2. 使用「噪音老電影音訊」→「人工降噪/修復版」配對訓練
3. 或使用更貼近老電影的噪音資料集（如磁帶噪音、光學音軌噪音）

**預期效果**：直接解決訓練/測試數據不匹配問題

### 選項 B：改用無監督/自監督方法
**原理**：不需要配對的乾淨/噪音數據

**可能方案**：
1. Noise2Noise：用噪音音訊訓練噪音音訊
2. 自監督降噪：利用音訊的時間連續性
3. GAN-based 方法：用判別器判斷音質

**優點**：可直接用真實老電影音訊訓練
**缺點**：需要重新設計架構和訓練流程

### 選項 C：改進 Loss 函數 
**問題**：MAE 無法反映人耳感知

**建議 Loss**：
```python
# 1. 多尺度 STFT Loss（頻域差異）
stft_loss = sum(|STFT(pred) - STFT(clean)|)

# 2. Perceptual Loss（預訓練音訊模型特徵）
perceptual_loss = |VGGish(pred) - VGGish(clean)|

# 3. 組合 Loss
total_loss = λ1*MAE + λ2*STFT + λ3*Perceptual
```

**預期效果**：模型學習更符合人耳感知的降噪

### 選項 D：使用現有老電影音訊直接微調
**前提**：需要少量配對數據（噪音版 + 手動降噪版）

**方案**：
1. 用現有模型作為預訓練權重
2. 用真實老電影配對數據微調（5-10 對即可）
3. 使用較小的 learning rate（1e-5）

**優點**：快速適應真實數據
**缺點**：需要手動製作配對數據

### 選項 E：暫時使用可調強度功能
**現狀**：已實作 `denoising_strength` 參數

**使用建議**：
```bash
# 嘗試不同強度找到最佳平衡
python3 inference.py --config-name conf_prototype \
  inference.audio=test_audio/file.wav \
  inference.denoising_strength=0.3  # 或 0.4, 0.5, 0.6, 0.7
```

**優點**：立即可用，無需重新訓練
**缺點**：治標不治本，只是線性混合

---

## 📊 實驗建議優先級

1. **高優先級**：選項 A（更換噪音源）- 根本解決問題
2. **中優先級**：選項 C（改進 Loss 函數）- 提升模型品質
3. **低優先級**：選項 B（無監督方法）- 需要大量開發時間
4. **暫時方案**：選項 E（可調強度）- 權宜之計

---

## 📝 技術筆記

### 配置文件
- **主配置**：`conf/conf_prototype.yaml`
- **資料集**：`conf/dset/dataset_prototype.yaml`
- **輸出位置**：`outputs/2026-02-03/HH-MM-SS/`

### 關鍵函數
- `generator_train()`：智能混合三種資料類型
- `generate_val_data()`：帶快取機制的驗證集生成
- `__noise_sample_generator()`：自適應噪音載入

### 快取策略
```python
cache_path = f".cache/dataset/val_data_{split}_{hash}.pkl"
# hash = MD5(sorted_paths + split + fs + seg_len_s)
```

---

## 🎓 經驗總結

1. **M3 晶片完全可行**：16GB RAM + batch_size=4 可穩定訓練
2. **快取機制必要**：將重複載入從分鐘級降到秒級
3. **驗證集大小要控制**：避免快取過大（每路徑 50 檔案為佳）
4. **Checkpoint 策略重要**：每 epoch 保存最佳模型避免浪費
5. **資料多樣性有效**：三種類型混合訓練，模型泛化能力更好

---

生成時間：2026年2月4日
模型狀態：✅ 已保存，可用於推理測試
